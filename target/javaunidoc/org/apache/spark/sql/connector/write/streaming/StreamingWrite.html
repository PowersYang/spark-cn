<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_181) on Tue Jan 14 17:50:02 CST 2020 -->
<title>StreamingWrite (Spark 3.0.0 JavaDoc)</title>
<meta name="date" content="2020-01-14">
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="StreamingWrite (Spark 3.0.0 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingDataWriterFactory.html" title="org.apache.spark.sql.connector.write.streaming中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li>下一个类</li>
</ul>
<ul class="navList">
<li><a href="../../../../../../../index.html?org/apache/spark/sql/connector/write/streaming/StreamingWrite.html" target="_top">框架</a></li>
<li><a href="StreamingWrite.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.connector.write.streaming</div>
<h2 title="接口 StreamingWrite" class="title">接口 StreamingWrite</h2>
</div>
<div class="contentContainer">
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>@Evolving
public interface <span class="typeNameLabel">StreamingWrite</span></pre>
<div class="block">An interface that defines how to write the data to data source in streaming queries.

 The writing procedure is:
   1. Create a writer factory by <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#createStreamingWriterFactory--"><code>createStreamingWriterFactory()</code></a>, serialize and send it to
      all the partitions of the input data(RDD).
   2. For each epoch in each partition, create the data writer, and write the data of the epoch in
      the partition with this writer. If all the data are written successfully, call
      <a href="../../../../../../../org/apache/spark/sql/connector/write/DataWriter.html#commit--"><code>DataWriter.commit()</code></a>. If exception happens during the writing, call
      <a href="../../../../../../../org/apache/spark/sql/connector/write/DataWriter.html#abort--"><code>DataWriter.abort()</code></a>.
   3. If writers in all partitions of one epoch are successfully committed, call
      <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#commit-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-"><code>commit(long, WriterCommitMessage[])</code></a>. If some writers are aborted, or the job failed
      with an unknown reason, call <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#abort-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-"><code>abort(long, WriterCommitMessage[])</code></a>.

 While Spark will retry failed writing tasks, Spark won't retry failed writing jobs. Users should
 do it manually in their Spark applications if they want to retry.

 Please refer to the documentation of commit/abort methods for detailed specifications.</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#abort-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-">abort</a></span>(long&nbsp;epochId,
     <a href="../../../../../../../org/apache/spark/sql/connector/write/WriterCommitMessage.html" title="org.apache.spark.sql.connector.write中的接口">WriterCommitMessage</a>[]&nbsp;messages)</code>
<div class="block">Aborts this writing job because some data writers are failed and keep failing when retried, or
 the Spark job fails with some unknown reasons, or <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#commit-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-"><code>commit(long, WriterCommitMessage[])</code></a>
 fails.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#commit-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-">commit</a></span>(long&nbsp;epochId,
      <a href="../../../../../../../org/apache/spark/sql/connector/write/WriterCommitMessage.html" title="org.apache.spark.sql.connector.write中的接口">WriterCommitMessage</a>[]&nbsp;messages)</code>
<div class="block">Commits this writing job for the specified epoch with a list of commit messages.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingDataWriterFactory.html" title="org.apache.spark.sql.connector.write.streaming中的接口">StreamingDataWriterFactory</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#createStreamingWriterFactory--">createStreamingWriterFactory</a></span>()</code>
<div class="block">Creates a writer factory which will be serialized and sent to executors.</div>
</td>
</tr>
</table>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="createStreamingWriterFactory--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createStreamingWriterFactory</h4>
<pre><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingDataWriterFactory.html" title="org.apache.spark.sql.connector.write.streaming中的接口">StreamingDataWriterFactory</a>&nbsp;createStreamingWriterFactory()</pre>
<div class="block">Creates a writer factory which will be serialized and sent to executors.

 If this method fails (by throwing an exception), the action will fail and no Spark job will be
 submitted.</div>
</li>
</ul>
<a name="commit-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>commit</h4>
<pre>void&nbsp;commit(long&nbsp;epochId,
            <a href="../../../../../../../org/apache/spark/sql/connector/write/WriterCommitMessage.html" title="org.apache.spark.sql.connector.write中的接口">WriterCommitMessage</a>[]&nbsp;messages)</pre>
<div class="block">Commits this writing job for the specified epoch with a list of commit messages. The commit
 messages are collected from successful data writers and are produced by
 <a href="../../../../../../../org/apache/spark/sql/connector/write/DataWriter.html#commit--"><code>DataWriter.commit()</code></a>.

 If this method fails (by throwing an exception), this writing job is considered to have been
 failed, and the execution engine will attempt to call
 <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#abort-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-"><code>abort(long, WriterCommitMessage[])</code></a>.

 The execution engine may call `commit` multiple times for the same epoch in some circumstances.
 To support exactly-once data semantics, implementations must ensure that multiple commits for
 the same epoch are idempotent.</div>
</li>
</ul>
<a name="abort-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>abort</h4>
<pre>void&nbsp;abort(long&nbsp;epochId,
           <a href="../../../../../../../org/apache/spark/sql/connector/write/WriterCommitMessage.html" title="org.apache.spark.sql.connector.write中的接口">WriterCommitMessage</a>[]&nbsp;messages)</pre>
<div class="block">Aborts this writing job because some data writers are failed and keep failing when retried, or
 the Spark job fails with some unknown reasons, or <a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html#commit-long-org.apache.spark.sql.connector.write.WriterCommitMessage:A-"><code>commit(long, WriterCommitMessage[])</code></a>
 fails.

 If this method fails (by throwing an exception), the underlying data source may require manual
 cleanup.

 Unless the abort is triggered by the failure of commit, the given messages will have some
 null slots, as there may be only a few data writers that were committed before the abort
 happens, or some data writers were committed but their commit messages haven't reached the
 driver when the abort is triggered. So this is just a "best effort" for data sources to
 clean up the data left by data writers.</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingDataWriterFactory.html" title="org.apache.spark.sql.connector.write.streaming中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li>下一个类</li>
</ul>
<ul class="navList">
<li><a href="../../../../../../../index.html?org/apache/spark/sql/connector/write/streaming/StreamingWrite.html" target="_top">框架</a></li>
<li><a href="StreamingWrite.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
