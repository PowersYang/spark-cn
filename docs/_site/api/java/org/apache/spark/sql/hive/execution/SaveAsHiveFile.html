<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_181) on Tue Jan 14 17:50:01 CST 2020 -->
<title>SaveAsHiveFile (Spark 3.0.0 JavaDoc)</title>
<meta name="date" content="2020-01-14">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="SaveAsHiveFile (Spark 3.0.0 JavaDoc)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6,"i3":6,"i4":6,"i5":6,"i6":6,"i7":6,"i8":6,"i9":6,"i10":6};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../org/apache/spark/sql/hive/execution/OptimizedCreateHiveTableAsSelectCommand.html" title="org.apache.spark.sql.hive.execution中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../org/apache/spark/sql/hive/execution/ScriptTransformationExec.html" title="org.apache.spark.sql.hive.execution中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/spark/sql/hive/execution/SaveAsHiveFile.html" target="_top">框架</a></li>
<li><a href="SaveAsHiveFile.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.apache.spark.sql.hive.execution</div>
<h2 title="接口 SaveAsHiveFile" class="title">接口 SaveAsHiveFile</h2>
</div>
<div class="contentContainer">
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>所有超级接口:</dt>
<dd>org.apache.spark.sql.catalyst.plans.logical.Command, org.apache.spark.sql.execution.command.DataWritingCommand</dd>
</dl>
<dl>
<dt>所有已知实现类:</dt>
<dd><a href="../../../../../../org/apache/spark/sql/hive/execution/InsertIntoHiveDirCommand.html" title="org.apache.spark.sql.hive.execution中的类">InsertIntoHiveDirCommand</a>, <a href="../../../../../../org/apache/spark/sql/hive/execution/InsertIntoHiveTable.html" title="org.apache.spark.sql.hive.execution中的类">InsertIntoHiveTable</a></dd>
</dl>
<hr>
<br>
<pre>public interface <span class="typeNameLabel">SaveAsHiveFile</span>
extends org.apache.spark.sql.execution.command.DataWritingCommand</pre>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>scala.Option&lt;org.apache.hadoop.fs.Path&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#createdTempDir--">createdTempDir</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#deleteExternalTmpPath-org.apache.hadoop.conf.Configuration-">deleteExternalTmpPath</a></span>(org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</code>&nbsp;</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#executionId--">executionId</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#getExternalScratchDir-java.net.URI-org.apache.hadoop.conf.Configuration-java.lang.String-">getExternalScratchDir</a></span>(java.net.URI&nbsp;extURI,
                     org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                     String&nbsp;stagingDir)</code>&nbsp;</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#getExternalTmpPath-org.apache.spark.sql.SparkSession-org.apache.hadoop.conf.Configuration-org.apache.hadoop.fs.Path-">getExternalTmpPath</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                  org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                  org.apache.hadoop.fs.Path&nbsp;path)</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#getExtTmpPathRelTo-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">getExtTmpPathRelTo</a></span>(org.apache.hadoop.fs.Path&nbsp;path,
                  org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                  String&nbsp;stagingDir)</code>&nbsp;</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#getStagingDir-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">getStagingDir</a></span>(org.apache.hadoop.fs.Path&nbsp;inputPath,
             org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
             String&nbsp;stagingDir)</code>&nbsp;</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#isSubDir-org.apache.hadoop.fs.Path-org.apache.hadoop.fs.Path-org.apache.hadoop.fs.FileSystem-">isSubDir</a></span>(org.apache.hadoop.fs.Path&nbsp;p1,
        org.apache.hadoop.fs.Path&nbsp;p2,
        org.apache.hadoop.fs.FileSystem&nbsp;fs)</code>&nbsp;</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#newVersionExternalTempPath-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">newVersionExternalTempPath</a></span>(org.apache.hadoop.fs.Path&nbsp;path,
                          org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                          String&nbsp;stagingDir)</code>&nbsp;</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>org.apache.hadoop.fs.Path</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#oldVersionExternalTempPath-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">oldVersionExternalTempPath</a></span>(org.apache.hadoop.fs.Path&nbsp;path,
                          org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                          String&nbsp;scratchDir)</code>&nbsp;</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>scala.collection.immutable.Set&lt;String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../../org/apache/spark/sql/hive/execution/SaveAsHiveFile.html#saveAsHiveFile-org.apache.spark.sql.SparkSession-org.apache.spark.sql.execution.SparkPlan-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.hive.HiveShim.ShimFileSinkDesc-java.lang.String-scala.collection.immutable.Map-scala.collection.Seq-">saveAsHiveFile</a></span>(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
              org.apache.spark.sql.execution.SparkPlan&nbsp;plan,
              org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
              org.apache.spark.sql.hive.HiveShim.ShimFileSinkDesc&nbsp;fileSinkConf,
              String&nbsp;outputLocation,
              scala.collection.immutable.Map&lt;scala.collection.immutable.Map&lt;String,String&gt;,String&gt;&nbsp;customPartitionLocations,
              scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;partitionAttributes)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.sql.execution.command.DataWritingCommand">
<!--   -->
</a>
<h3>从接口继承的方法&nbsp;org.apache.spark.sql.execution.command.DataWritingCommand</h3>
<code>$init$, basicWriteJobStatsTracker, children, logicalPlanOutputWithNames, metrics, outputColumnNames, outputColumns, query, run</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.org.apache.spark.sql.catalyst.plans.logical.Command">
<!--   -->
</a>
<h3>从接口继承的方法&nbsp;org.apache.spark.sql.catalyst.plans.logical.Command</h3>
<code>$init$, output</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="createdTempDir--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createdTempDir</h4>
<pre>scala.Option&lt;org.apache.hadoop.fs.Path&gt;&nbsp;createdTempDir()</pre>
</li>
</ul>
<a name="deleteExternalTmpPath-org.apache.hadoop.conf.Configuration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>deleteExternalTmpPath</h4>
<pre>void&nbsp;deleteExternalTmpPath(org.apache.hadoop.conf.Configuration&nbsp;hadoopConf)</pre>
</li>
</ul>
<a name="executionId--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>executionId</h4>
<pre>String&nbsp;executionId()</pre>
</li>
</ul>
<a name="getExtTmpPathRelTo-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getExtTmpPathRelTo</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;getExtTmpPathRelTo(org.apache.hadoop.fs.Path&nbsp;path,
                                             org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                             String&nbsp;stagingDir)</pre>
</li>
</ul>
<a name="getExternalScratchDir-java.net.URI-org.apache.hadoop.conf.Configuration-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getExternalScratchDir</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;getExternalScratchDir(java.net.URI&nbsp;extURI,
                                                org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                                String&nbsp;stagingDir)</pre>
</li>
</ul>
<a name="getExternalTmpPath-org.apache.spark.sql.SparkSession-org.apache.hadoop.conf.Configuration-org.apache.hadoop.fs.Path-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getExternalTmpPath</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;getExternalTmpPath(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                             org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                             org.apache.hadoop.fs.Path&nbsp;path)</pre>
</li>
</ul>
<a name="getStagingDir-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getStagingDir</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;getStagingDir(org.apache.hadoop.fs.Path&nbsp;inputPath,
                                        org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                        String&nbsp;stagingDir)</pre>
</li>
</ul>
<a name="isSubDir-org.apache.hadoop.fs.Path-org.apache.hadoop.fs.Path-org.apache.hadoop.fs.FileSystem-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isSubDir</h4>
<pre>boolean&nbsp;isSubDir(org.apache.hadoop.fs.Path&nbsp;p1,
                 org.apache.hadoop.fs.Path&nbsp;p2,
                 org.apache.hadoop.fs.FileSystem&nbsp;fs)</pre>
</li>
</ul>
<a name="newVersionExternalTempPath-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>newVersionExternalTempPath</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;newVersionExternalTempPath(org.apache.hadoop.fs.Path&nbsp;path,
                                                     org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                                     String&nbsp;stagingDir)</pre>
</li>
</ul>
<a name="oldVersionExternalTempPath-org.apache.hadoop.fs.Path-org.apache.hadoop.conf.Configuration-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>oldVersionExternalTempPath</h4>
<pre>org.apache.hadoop.fs.Path&nbsp;oldVersionExternalTempPath(org.apache.hadoop.fs.Path&nbsp;path,
                                                     org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                                     String&nbsp;scratchDir)</pre>
</li>
</ul>
<a name="saveAsHiveFile-org.apache.spark.sql.SparkSession-org.apache.spark.sql.execution.SparkPlan-org.apache.hadoop.conf.Configuration-org.apache.spark.sql.hive.HiveShim.ShimFileSinkDesc-java.lang.String-scala.collection.immutable.Map-scala.collection.Seq-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>saveAsHiveFile</h4>
<pre>scala.collection.immutable.Set&lt;String&gt;&nbsp;saveAsHiveFile(<a href="../../../../../../org/apache/spark/sql/SparkSession.html" title="org.apache.spark.sql中的类">SparkSession</a>&nbsp;sparkSession,
                                                      org.apache.spark.sql.execution.SparkPlan&nbsp;plan,
                                                      org.apache.hadoop.conf.Configuration&nbsp;hadoopConf,
                                                      org.apache.spark.sql.hive.HiveShim.ShimFileSinkDesc&nbsp;fileSinkConf,
                                                      String&nbsp;outputLocation,
                                                      scala.collection.immutable.Map&lt;scala.collection.immutable.Map&lt;String,String&gt;,String&gt;&nbsp;customPartitionLocations,
                                                      scala.collection.Seq&lt;org.apache.spark.sql.catalyst.expressions.Attribute&gt;&nbsp;partitionAttributes)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../../../../index-all.html">索引</a></li>
<li><a href="../../../../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../../../org/apache/spark/sql/hive/execution/OptimizedCreateHiveTableAsSelectCommand.html" title="org.apache.spark.sql.hive.execution中的类"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../../../../org/apache/spark/sql/hive/execution/ScriptTransformationExec.html" title="org.apache.spark.sql.hive.execution中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../../../index.html?org/apache/spark/sql/hive/execution/SaveAsHiveFile.html" target="_top">框架</a></li>
<li><a href="SaveAsHiveFile.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<script defer="defer" type="text/javascript" src="../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" src="../../../../../../lib/api-javadocs.js"></script></body>
</html>
