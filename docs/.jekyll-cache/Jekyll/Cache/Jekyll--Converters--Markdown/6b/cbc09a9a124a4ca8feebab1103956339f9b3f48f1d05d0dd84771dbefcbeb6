I"¦<ul id="markdown-toc">
  <li><a href="#å®‰å…¨" id="markdown-toc-å®‰å…¨">å®‰å…¨</a></li>
  <li><a href="#ä½¿ç”¨spark-shellè¿›è¡Œäº¤äº’å¼åˆ†æ" id="markdown-toc-ä½¿ç”¨spark-shellè¿›è¡Œäº¤äº’å¼åˆ†æ">ä½¿ç”¨Spark Shellè¿›è¡Œäº¤äº’å¼åˆ†æ</a>    <ul>
      <li><a href="#åŸºç¡€" id="markdown-toc-åŸºç¡€">åŸºç¡€</a></li>
      <li><a href="#æœ‰å…³æ•°æ®é›†æ“ä½œçš„æ›´å¤šä¿¡æ¯" id="markdown-toc-æœ‰å…³æ•°æ®é›†æ“ä½œçš„æ›´å¤šä¿¡æ¯">æœ‰å…³æ•°æ®é›†æ“ä½œçš„æ›´å¤šä¿¡æ¯</a></li>
      <li><a href="#ç¼“å­˜" id="markdown-toc-ç¼“å­˜">ç¼“å­˜</a></li>
    </ul>
  </li>
  <li><a href="#ç‹¬ç«‹çš„åº”ç”¨" id="markdown-toc-ç‹¬ç«‹çš„åº”ç”¨">ç‹¬ç«‹çš„åº”ç”¨</a></li>
  <li><a href="#ä¸‹ä¸€æ­¥åšä»€ä¹ˆ" id="markdown-toc-ä¸‹ä¸€æ­¥åšä»€ä¹ˆ">ä¸‹ä¸€æ­¥åšä»€ä¹ˆ</a></li>
</ul>
<p>æœ¬æ•™ç¨‹æä¾›äº†ä½¿ç”¨Sparkçš„å¿«é€Ÿä»‹ç»ã€‚æˆ‘ä»¬å°†é¦–å…ˆé€šè¿‡Sparkçš„äº¤äº’å¼Shellï¼ˆåœ¨Pythonæˆ–Scalaä¸­ï¼‰ä»‹ç»APIï¼Œç„¶åå±•ç¤ºå¦‚ä½•ç”¨Javaï¼ŒScalaå’ŒPythonç¼–å†™åº”ç”¨ç¨‹åºã€‚</p>

<p>è¦å­¦ä¹ æœ¬æŒ‡å—ï¼Œè¯·é¦–å…ˆä»<a href="https://spark.apache.org/downloads.html">Sparkç½‘ç«™</a>ä¸‹è½½Sparkçš„packageç‰ˆæœ¬ ã€‚ç”±äºæˆ‘ä»¬ä¸ä¼šä½¿ç”¨HDFSï¼Œå› æ­¤ä½ å¯ä»¥ä¸‹è½½ä»»ä½•ç‰ˆæœ¬çš„Hadoopã€‚</p>

<p>è¯·æ³¨æ„ï¼Œåœ¨Spark 2.0ä¹‹å‰ï¼ŒSparkçš„ä¸»è¦ç¼–ç¨‹æ¥å£æ˜¯å¼¹æ€§åˆ†å¸ƒå¼æ•°æ®é›†ï¼ˆRDDï¼‰ã€‚åœ¨Spark 2.0ä¹‹åï¼ŒRDDè¢«Datasetå–ä»£ï¼ŒDatasetçš„ç±»å‹åƒRDDä¸€æ ·å¼ºï¼Œä½†å…·æœ‰æ›´ä¸°å¯Œçš„ä¼˜åŒ–åŠŸèƒ½ã€‚ä»æ”¯æŒRDDç•Œé¢ï¼Œä½ å¯ä»¥åœ¨<a href="rdd-programming-guide.html">RDDç¼–ç¨‹æŒ‡å—ä¸­</a>è·å¾—æ›´è¯¦ç»†çš„å‚è€ƒã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ åˆ‡æ¢åˆ°ä½¿ç”¨æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†çš„æ€§èƒ½æ¯”RDDæ›´å¥½ã€‚è¯·å‚é˜…ã€Š<a href="sql-programming-guide.html">SQLç¼–ç¨‹æŒ‡å—ã€‹</a>ä»¥è·å–æœ‰å…³æ•°æ®é›†çš„æ›´å¤šä¿¡æ¯ã€‚</p>

<h1 id="å®‰å…¨">å®‰å…¨</h1>

<p>é»˜è®¤æƒ…å†µä¸‹ï¼ŒSparkä¸­çš„å®‰å…¨æ€§å¤„äºå…³é—­çŠ¶æ€ã€‚è¿™å¯èƒ½æ„å‘³ç€ä½ é»˜è®¤æƒ…å†µä¸‹å®¹æ˜“å—åˆ°æ”»å‡»ã€‚è¿è¡ŒSparkä¹‹å‰ï¼Œè¯·å‚é˜…<a href="security.html">Spark Security</a>ã€‚</p>

<h1 id="ä½¿ç”¨spark-shellè¿›è¡Œäº¤äº’å¼åˆ†æ">ä½¿ç”¨Spark Shellè¿›è¡Œäº¤äº’å¼åˆ†æ</h1>

<h2 id="åŸºç¡€">åŸºç¡€</h2>

<p>Spark shellæä¾›äº†å­¦ä¹ APIçš„ç®€å•æ–¹æ³•ï¼Œä»¥åŠå¼ºå¤§çš„å·¥å…·æ¥äº¤äº’å¼åœ°åˆ†ææ•°æ®ã€‚å®ƒå¯ä»¥åœ¨Scalaï¼ˆå¯åœ¨Java VMä¸Šè¿è¡Œï¼Œå› æ­¤æ˜¯ä½¿ç”¨ç°æœ‰Javaåº“çš„å¥½æ–¹æ³•ï¼‰æˆ–Pythonä¸­æä¾›ã€‚é€šè¿‡åœ¨Sparkç›®å½•ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å¯åŠ¨å®ƒï¼š</p>

<div class="codetabs">
<div data-lang="scala">

    <pre><code>./bin/spark-shell
</code></pre>

    <p>Sparkçš„ä¸»è¦æŠ½è±¡æ˜¯ç§°ä¸ºDatasetçš„åˆ†å¸ƒå¼é›†åˆã€‚å¯ä»¥ä»Hadoop InputFormatsï¼ˆä¾‹å¦‚HDFSæ–‡ä»¶ï¼‰æˆ–é€šè¿‡è½¬æ¢å…¶ä»–æ•°æ®é›†æ¥åˆ›å»ºDataSetã€‚è®©æˆ‘ä»¬ä»Sparkæºç›®å½•ä¸­çš„READMEæ–‡ä»¶çš„æ–‡æœ¬ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">textFile</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"README.md"</span><span class="o">)</span>
<span class="n">textFile</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.Dataset</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">value:</span> <span class="kt">string</span><span class="o">]</span></code></pre></figure>

    <p>ä½ å¯ä»¥é€šè¿‡è°ƒç”¨æŸäº›æ“ä½œç›´æ¥ä»æ•°æ®é›†ä¸­è·å–å€¼ï¼Œæˆ–è½¬æ¢æ•°æ®é›†ä»¥è·å–æ–°å€¼ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·é˜…è¯»<em><a href="api/scala/index.html#org.apache.spark.sql.Dataset">APIæ–‡æ¡£</a></em>ã€‚</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">count</span><span class="o">()</span> <span class="c1">// Number of items in this Dataset
</span><span class="n">res0</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">126</span> <span class="c1">// May be different from yours as README.md will change over time, similar to other outputs
</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">first</span><span class="o">()</span> <span class="c1">// First item in this Dataset
</span><span class="n">res1</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="k">#</span> <span class="nc">Apache</span> <span class="nc">Spark</span></code></pre></figure>

    <p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†æ­¤æ•°æ®é›†è½¬æ¢ä¸ºæ–°çš„æ•°æ®é›†ã€‚æˆ‘ä»¬è°ƒç”¨<code>filter</code>è¿”å›ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«æ–‡ä»¶ä¸­é¡¹çš„å­é›†ã€‚</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">linesWithSpark</span> <span class="k">=</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">contains</span><span class="o">(</span><span class="s">"Spark"</span><span class="o">))</span>
<span class="n">linesWithSpark</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.Dataset</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">value:</span> <span class="kt">string</span><span class="o">]</span></code></pre></figure>

    <p>æˆ‘ä»¬å¯ä»¥å°†è½¬æ¢å’ŒåŠ¨ä½œé“¾æ¥åœ¨ä¸€èµ·ï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">contains</span><span class="o">(</span><span class="s">"Spark"</span><span class="o">)).</span><span class="py">count</span><span class="o">()</span> <span class="c1">// How many lines contain "Spark"?
</span><span class="n">res3</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">15</span></code></pre></figure>

  </div>
<div data-lang="python">

    <pre><code>./bin/pyspark
</code></pre>

    <p>æˆ–è€…åœ¨å½“å‰ç¯å¢ƒä¸­ä½¿ç”¨pipå®‰è£…PySparkçš„åŒ…ï¼š</p>

    <pre><code>pyspark
</code></pre>

    <p>Sparkçš„ä¸»è¦æŠ½è±¡æ˜¯ç§°ä¸ºæ•°æ®é›†çš„é¡¹ç›®çš„åˆ†å¸ƒå¼é›†åˆã€‚å¯ä»¥ä»Hadoop InputFormatsï¼ˆä¾‹å¦‚HDFSæ–‡ä»¶ï¼‰æˆ–é€šè¿‡è½¬æ¢å…¶ä»–æ•°æ®é›†æ¥åˆ›å»ºæ•°æ®é›†ã€‚ç”±äºPythonçš„åŠ¨æ€æ€§è´¨ï¼Œæˆ‘ä»¬ä¸éœ€è¦åœ¨Pythonä¸­å¯¹æ•°æ®é›†è¿›è¡Œå¼ºç±»å‹åŒ–ã€‚Pythonä¸­çš„æ‰€æœ‰æ•°æ®é›†éƒ½æ˜¯Dataset [Row]ï¼Œæˆ‘ä»¬ç§°å…¶<code>DataFrame</code>ä¸Pandaså’ŒRä¸­çš„æ•°æ®æ¡†æ¦‚å¿µä¸€è‡´ã€‚è®©æˆ‘ä»¬ä»Sparkæºç›®å½•ä¸­çš„READMEæ–‡ä»¶çš„æ–‡æœ¬ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameï¼š</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">textFile</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="s">"README.md"</span><span class="p">)</span></code></pre></figure>

    <p>ä½ å¯ä»¥é€šè¿‡è°ƒç”¨ä¸€äº›æ“ä½œç›´æ¥ä»DataFrameä¸­è·å–å€¼ï¼Œæˆ–è½¬æ¢DataFrameä»¥è·å–æ–°çš„å€¼ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·é˜…è¯»<em><a href="api/python/index.html#pyspark.sql.DataFrame">APIæ–‡æ¡£</a></em>ã€‚</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># Number of rows in this DataFrame
</span><span class="mi">126</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>  <span class="c1"># First row in this DataFrame
</span><span class="n">Row</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s">u'# Apache Spark'</span><span class="p">)</span></code></pre></figure>

    <p>ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†æ­¤DataFrameè½¬æ¢ä¸ºä¸€ä¸ªæ–°çš„ã€‚æˆ‘ä»¬è°ƒç”¨<code>filter</code>è¿”å›ä¸€ä¸ªæ–°çš„DataFrameï¼Œå…¶ä¸­åŒ…å«æ–‡ä»¶ä¸­å„è¡Œçš„å­é›†ã€‚</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">linesWithSpark</span> <span class="o">=</span> <span class="n">textFile</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">textFile</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s">"Spark"</span><span class="p">))</span></code></pre></figure>

    <p>æˆ‘ä»¬å¯ä»¥å°†è½¬æ¢å’ŒåŠ¨ä½œé“¾æ¥åœ¨ä¸€èµ·ï¼š</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">textFile</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s">"Spark"</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>  <span class="c1"># How many lines contain "Spark"?
</span><span class="mi">15</span></code></pre></figure>

  </div>
</div>

<h2 id="æœ‰å…³æ•°æ®é›†æ“ä½œçš„æ›´å¤šä¿¡æ¯">æœ‰å…³æ•°æ®é›†æ“ä½œçš„æ›´å¤šä¿¡æ¯</h2>

<p>DataSetåŠ¨ä½œå’Œè½¬æ¢å¯ç”¨äºæ›´å¤æ‚çš„è®¡ç®—ã€‚å‡è®¾æˆ‘ä»¬è¦æŸ¥æ‰¾åŒ…å«æœ€å¤šå•è¯çš„è¡Œï¼š</p>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">" "</span><span class="o">).</span><span class="py">size</span><span class="o">).</span><span class="py">reduce</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nf">if</span> <span class="o">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="n">b</span><span class="o">)</span> <span class="n">a</span> <span class="k">else</span> <span class="n">b</span><span class="o">)</span>
<span class="n">res4</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">15</span></code></pre></figure>

    <p>é¦–å…ˆï¼Œå°†ä¸€è¡Œå†…å®¹æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°å€¼ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„DataSetã€‚<code>reduce</code>åœ¨è¯¥æ•°æ®é›†ä¸Šè°ƒç”¨ï¼Œä»¥æ‰¾åˆ°æœ€å¤§çš„å­—æ•°ã€‚ä¼ ç»™<code>map</code>å’Œ<code>reduce</code>çš„å‚æ•°æ˜¯Scalaçš„é—­åŒ…å‡½æ•°ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨Scalaå’ŒJavaçš„åº“å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åœ¨å…¶ä»–åœ°æ–¹è°ƒç”¨å£°æ˜çš„å‡½æ•°ã€‚æˆ‘ä»¬å°†ä½¿ç”¨<code>Math.max()</code>å‡½æ•°ä½¿æ­¤ä»£ç æ›´æ˜“äºç†è§£ï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">import</span> <span class="nn">java.lang.Math</span>
<span class="k">import</span> <span class="nn">java.lang.Math</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">" "</span><span class="o">).</span><span class="py">size</span><span class="o">).</span><span class="py">reduce</span><span class="o">((</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nv">Math</span><span class="o">.</span><span class="py">max</span><span class="o">(</span><span class="n">a</span><span class="o">,</span> <span class="n">b</span><span class="o">))</span>
<span class="n">res5</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">15</span></code></pre></figure>

    <p>ä¸€ç§å¸¸è§çš„æ•°æ®æµæ¨¡å¼æ˜¯Hadoopæµè¡Œçš„MapReduceã€‚Sparkå¯ä»¥è½»æ¾å®ç°MapReduceæµï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">wordCounts</span> <span class="k">=</span> <span class="nv">textFile</span><span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">" "</span><span class="o">)).</span><span class="py">groupByKey</span><span class="o">(</span><span class="n">identity</span><span class="o">).</span><span class="py">count</span><span class="o">()</span>
<span class="n">wordCounts</span><span class="k">:</span> <span class="kt">org.apache.spark.sql.Dataset</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="o">[</span><span class="kt">value:</span> <span class="kt">string</span>, <span class="kt">count</span><span class="o">(</span><span class="err">1</span><span class="o">)</span><span class="kt">:</span> <span class="kt">bigint</span><span class="o">]</span></code></pre></figure>

    <p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è°ƒç”¨<code>flatMap</code>å°†è¡Œçš„æ•°æ®é›†è½¬æ¢ä¸ºå•è¯çš„æ•°æ®é›†ï¼Œç„¶åç»„åˆ<code>groupByKey</code>å¹¶ä½¿ç”¨<code>count</code>æ¥è®¡ç®—æ–‡ä»¶ä¸­æ¯ä¸ªå•è¯çš„è®¡æ•°ï¼Œæœ€åè¿”å›ï¼ˆString, Longï¼‰ç±»å‹çš„æ•°æ®å¯¹ã€‚è¦æ”¶é›†shellä¸­çš„æ•°æ®ï¼Œå¯ä»¥è°ƒç”¨<code>collect</code>ï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">wordCounts</span><span class="o">.</span><span class="py">collect</span><span class="o">()</span>
<span class="n">res6</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">((</span><span class="n">means</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="n">under</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">3</span><span class="o">),</span> <span class="o">(</span><span class="nc">Because</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="nc">Python</span><span class="o">,</span><span class="mi">2</span><span class="o">),</span> <span class="o">(</span><span class="n">agree</span><span class="o">,</span><span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="n">cluster</span><span class="o">.,</span><span class="mi">1</span><span class="o">),</span> <span class="o">...)</span></code></pre></figure>

  </div>
<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">textFile</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">split</span><span class="p">(</span><span class="n">textFile</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="s">"</span><span class="err">\</span><span class="s">s+"</span><span class="p">))</span><span class="o">.</span><span class="n">name</span><span class="p">(</span><span class="s">"numWords"</span><span class="p">))</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">"numWords"</span><span class="p">)))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="p">[</span><span class="n">Row</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span><span class="o">=</span><span class="mi">15</span><span class="p">)]</span></code></pre></figure>

    <p>é¦–å…ˆï¼Œå°†ä¸€è¡Œå†…å®¹æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°å€¼ï¼Œå¹¶å°†å…¶å–åä¸ºâ€œ numWordsâ€ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameã€‚åœ¨è¯¥DataFrameä¸Šè°ƒç”¨<code>agg</code>ä»¥æ‰¾åˆ°æœ€å¤§çš„å­—æ•°ã€‚ä¼ ç»™<code>select</code>å’Œ<code>agg</code>çš„å‚æ•°éƒ½æ˜¯<em><a href="api/python/index.html#pyspark.sql.Column">Columnå¯¹è±¡</a></em>ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code>df.colName</code>ä»DataFrameä¸­è·å¾—ä¸€åˆ—ã€‚æˆ‘ä»¬è¿˜å¯ä»¥å¯¼å…¥pyspark.sql.functionsï¼Œå®ƒæä¾›äº†è®¸å¤šä»æ—§çš„åˆ—æ„å»ºæ–°åˆ—çš„å‡½æ•°ã€‚</p>

    <p>ä¸€ç§å¸¸è§çš„æ•°æ®æµæ¨¡å¼æ˜¯Hadoopæµè¡Œçš„MapReduceã€‚Sparkå¯ä»¥è½»æ¾å®ç°MapReduceæµ</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">textFile</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">explode</span><span class="p">(</span><span class="n">split</span><span class="p">(</span><span class="n">textFile</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="s">"</span><span class="err">\</span><span class="s">s+"</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">"word"</span><span class="p">))</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">"word"</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span></code></pre></figure>

    <p>è¿™é‡Œæˆ‘ä»¬åœ¨ <code>select</code>ä¸­ä½¿ç”¨äº† <code>explode</code> å‡½æ•°å°†è¡Œçš„æ•°æ®é›†è½¬æ¢ä¸ºå•è¯çš„æ•°æ®é›†ï¼Œç„¶åç»“åˆ <code>groupBy</code> å’Œ <code>count</code> æ¥è®¡ç®—æ¯ä¸€ä¸ªå•è¯åœ¨æ–‡ä»¶ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œæœ€åè¾“å‡ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªColumnï¼ˆ&#8221;word&#8221; and &#8220;count&#8221;ï¼‰çš„DataFrameã€‚ å¯ä»¥ä½¿ç”¨ <code>collect</code>å‡½æ•°æ”¶é›†è®¡ç®—ç»“æœï¼š</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">wordCounts</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="p">[</span><span class="n">Row</span><span class="p">(</span><span class="n">word</span><span class="o">=</span><span class="s">u'online'</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="n">word</span><span class="o">=</span><span class="s">u'graphs'</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="o">...</span><span class="p">]</span></code></pre></figure>

  </div>
</div>

<h2 id="ç¼“å­˜">ç¼“å­˜</h2>

<p>Sparkè¿˜æ”¯æŒå°†æ•°æ®é›†æå–åˆ°é›†ç¾¤èŒƒå›´çš„å†…å­˜ç¼“å­˜ä¸­ã€‚å½“é‡å¤è®¿é—®æ¯”è¾ƒå°çš„æ•°æ®é›†æˆ–è¿è¡Œè¿­ä»£ç®—æ³•ï¼ˆå¦‚PageRankï¼‰æ—¶ï¼Œè¿™éå¸¸æœ‰ç”¨ã€‚ä¸¾ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œè®©æˆ‘ä»¬æ ‡è®°<code>linesWithSpark</code>è¦ç¼“å­˜çš„æ•°æ®é›†ï¼š</p>

<div class="codetabs">
<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">linesWithSpark</span><span class="o">.</span><span class="py">cache</span><span class="o">()</span>
<span class="n">res7</span><span class="k">:</span> <span class="kt">linesWithSpark.</span><span class="k">type</span> <span class="o">=</span> <span class="o">[</span><span class="kt">value:</span> <span class="kt">string</span><span class="o">]</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">linesWithSpark</span><span class="o">.</span><span class="py">count</span><span class="o">()</span>
<span class="n">res8</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">linesWithSpark</span><span class="o">.</span><span class="py">count</span><span class="o">()</span>
<span class="n">res9</span><span class="k">:</span> <span class="kt">Long</span> <span class="o">=</span> <span class="mi">15</span></code></pre></figure>

    <p>ä½¿ç”¨Sparkè®¡ç®—å’Œç¼“å­˜100è¡Œæ–‡æœ¬æ–‡ä»¶ä¼¼ä¹å¾ˆæ„šè ¢ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå³ä½¿åœ¨æ•°åæˆ–æ•°ç™¾ä¸ªèŠ‚ç‚¹ä¸Šï¼Œè¿™äº›ç›¸åŒçš„å‡½æ•°ä¹Ÿå¯ä»¥ç”¨äºéå¸¸å¤§çš„æ•°æ®é›†ã€‚ä½ ä¹Ÿå¯ä»¥<code>bin/spark-shell</code>æŒ‰ç…§<a href="rdd-programming-guide.html#using-the-shell">RDDç¼–ç¨‹æŒ‡å—</a>ä¸­çš„è¯´æ˜ï¼Œé€šè¿‡è¿æ¥åˆ°è®¡ç®—ä»¥äº¤äº’çš„æ–¹å¼è¿›è¡Œæ“ä½œã€‚</p>

  </div>

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">&gt;&gt;&gt;</span> <span class="n">linesWithSpark</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">linesWithSpark</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">15</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">linesWithSpark</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="mi">15</span></code></pre></figure>

    <p>ä½¿ç”¨Sparkè®¡ç®—å’Œç¼“å­˜100è¡Œæ–‡æœ¬æ–‡ä»¶ä¼¼ä¹å¾ˆæ„šè ¢ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå³ä½¿åœ¨æ•°åæˆ–æ•°ç™¾ä¸ªèŠ‚ç‚¹ä¸Šï¼Œè¿™äº›ç›¸åŒçš„å‡½æ•°ä¹Ÿå¯ä»¥ç”¨äºéå¸¸å¤§çš„æ•°æ®é›†ã€‚ä½ ä¹Ÿå¯ä»¥<code>bin/pyspark</code>æŒ‰ç…§<a href="rdd-programming-guide.html#using-the-shell">RDDç¼–ç¨‹æŒ‡å—</a>ä¸­çš„è¯´æ˜ï¼Œé€šè¿‡è¿æ¥åˆ°è®¡ç®—ä»¥äº¤äº’çš„æ–¹å¼è¿›è¡Œæ“ä½œã€‚</p>

  </div>
</div>

<h1 id="ç‹¬ç«‹çš„åº”ç”¨">ç‹¬ç«‹çš„åº”ç”¨</h1>
<p>å‡è®¾æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨Spark APIç¼–å†™ä¸€ä¸ªç‹¬ç«‹çš„åº”ç”¨ç¨‹åºã€‚æˆ‘ä»¬å°†é€æ­¥ä»‹ç»ä¸€ä¸ªScalaï¼ˆå¸¦æœ‰sbtï¼‰ï¼ŒJavaï¼ˆå¸¦æœ‰Mavenï¼‰å’ŒPythonï¼ˆpipï¼‰çš„ç®€å•åº”ç”¨ç¨‹åºã€‚</p>

<div class="codetabs">
<div data-lang="scala">
    <p>æˆ‘ä»¬å°†åœ¨Scalaä¸­åˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„Sparkåº”ç”¨ç¨‹åºï¼Œåä¸º<code>SimpleApp.scala</code>ï¼š</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="cm">/* SimpleApp.scala */</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="k">object</span> <span class="nc">SimpleApp</span> <span class="o">{</span>
  <span class="k">def</span> <span class="nf">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="k">val</span> <span class="nv">logFile</span> <span class="k">=</span> <span class="s">"YOUR_SPARK_HOME/README.md"</span> <span class="c1">// Should be some file on your system
</span>    <span class="k">val</span> <span class="nv">spark</span> <span class="k">=</span> <span class="nv">SparkSession</span><span class="o">.</span><span class="py">builder</span><span class="o">.</span><span class="py">appName</span><span class="o">(</span><span class="s">"Simple Application"</span><span class="o">).</span><span class="py">getOrCreate</span><span class="o">()</span>
    <span class="k">val</span> <span class="nv">logData</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="n">logFile</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
    <span class="k">val</span> <span class="nv">numAs</span> <span class="k">=</span> <span class="nv">logData</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">contains</span><span class="o">(</span><span class="s">"a"</span><span class="o">)).</span><span class="py">count</span><span class="o">()</span>
    <span class="k">val</span> <span class="nv">numBs</span> <span class="k">=</span> <span class="nv">logData</span><span class="o">.</span><span class="py">filter</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="nv">line</span><span class="o">.</span><span class="py">contains</span><span class="o">(</span><span class="s">"b"</span><span class="o">)).</span><span class="py">count</span><span class="o">()</span>
    <span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"Lines with a: $numAs, Lines with b: $numBs"</span><span class="o">)</span>
    <span class="nv">spark</span><span class="o">.</span><span class="py">stop</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

    <p>æ³¨æ„ï¼Œè¿™ä¸ªåº”ç”¨ç¨‹åºæˆ‘ä»¬åº”è¯¥å®šä¹‰ä¸€ä¸ª <code>main()</code> æ–¹æ³•è€Œä¸æ˜¯å»ç»§æ‰¿scala.App<code>ã€‚ä½¿ç”¨ </code>scala.App` çš„å­ç±»å¯èƒ½ä¸ä¼šæ­£å¸¸è¿è¡Œã€‚</p>

    <p>è¯¥ç¨‹åºåªè®¡ç®—Spark READMEæ–‡ä»¶ä¸­åŒ…å«â€œ aâ€çš„è¡Œæ•°å’ŒåŒ…å«â€œ bâ€çš„è¡Œæ•°ã€‚è¯·æ³¨æ„ï¼Œä½ éœ€è¦å°†YOUR_SPARK_HOMEæ›¿æ¢ä¸ºä½ è‡ªå·±ç”µè„‘ä¸­Sparkçš„å®‰è£…è·¯å¾„ã€‚ä¸å‰é¢å¸¦æœ‰Spark shellçš„ç¤ºä¾‹ï¼ˆå…¶åˆå§‹åŒ–å…¶è‡ªå·±çš„SparkSessionï¼‰ä¸åŒï¼Œæˆ‘ä»¬å°†SparkSessionåˆå§‹åŒ–ä¸ºç¨‹åºçš„ä¸€éƒ¨åˆ†ã€‚</p>

    <p>æˆ‘ä»¬è°ƒç”¨<code>SparkSession.builder</code>æ„é€ ä¸€ä¸ª[[SparkSession]]ï¼Œç„¶åè®¾ç½®åº”ç”¨ç¨‹åºåç§°ï¼Œæœ€åè°ƒç”¨<code>getOrCreate</code>ä»¥è·å¾—[[SparkSession]]å®ä¾‹ã€‚</p>

    <p>æˆ‘ä»¬çš„åº”ç”¨ä¾èµ–äº† Spark APIï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åŒ…å«ä¸€ä¸ªåä¸º <code>build.sbt</code> çš„ sbt é…ç½®æ–‡ä»¶ï¼Œå®ƒæè¿°äº† Spark çš„ä¾èµ–ã€‚è¯¥æ–‡ä»¶ä¹Ÿä¼šæ·»åŠ ä¸€ä¸ª Spark ä¾èµ–çš„ repository:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">name</span> <span class="o">:=</span> <span class="s">"Simple Project"</span>

<span class="n">version</span> <span class="o">:=</span> <span class="s">"1.0"</span>

<span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">"2.12.10"</span>

<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">"org.apache.spark"</span> <span class="o">%%</span> <span class="s">"spark-sql"</span> <span class="o">%</span> <span class="s">"3.0.0-SNAPSHOT"</span></code></pre></figure>

    <p>ä¸ºäº†è®© sbt æ­£å¸¸è¿è¡Œï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®ç»å…¸çš„ç›®å½•ç»“æ„æ¥å¸ƒå±€ <code>SimpleApp.scala</code> å’Œ <code>build.sbt</code> æ–‡ä»¶ã€‚åœ¨æˆåŠŸåï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«åº”ç”¨ç¨‹åºä»£ç çš„ JAR åŒ…ï¼Œç„¶åä½¿ç”¨ <code>spark-submit</code> è„šæœ¬æ¥è¿è¡Œæˆ‘ä»¬çš„ç¨‹åºã€‚</p>

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ä½ çš„ç›®å½•ç»“æ„åº”è¯¥æ˜¯è¿™æ ·å­çš„</span>
<span class="nv">$ </span>find <span class="nb">.</span>
<span class="nb">.</span>
./build.sbt
./src
./src/main
./src/main/scala
./src/main/scala/SimpleApp.scala

<span class="c"># å°†ä½ çš„ç¨‹åºæ‰“åŒ…</span>
<span class="nv">$ </span>sbt package
...
<span class="o">[</span>info] Packaging <span class="o">{</span>..<span class="o">}</span>/<span class="o">{</span>..<span class="o">}</span>/target/scala-2.12/simple-project_2.12-1.0.jar

<span class="c"># ä½¿ç”¨spark-submitè¿è¡Œä½ çš„ç¨‹åº</span>
<span class="nv">$ </span>YOUR_SPARK_HOME/bin/spark-submit <span class="se">\</span>
  <span class="nt">--class</span> <span class="s2">"SimpleApp"</span> <span class="se">\</span>
  <span class="nt">--master</span> <span class="nb">local</span><span class="o">[</span>4] <span class="se">\</span>
  target/scala-2.12/simple-project_2.12-1.0.jar
...
Lines with a: 46, Lines with b: 23</code></pre></figure>

  </div>

<div data-lang="java">
    <p>æœ¬ç¤ºä¾‹å°†ä½¿ç”¨Mavenç¼–è¯‘åº”ç”¨ç¨‹åºçš„JARåŒ…ï¼Œä½†æ˜¯ç±»ä¼¼çš„æ„å»ºå·¥å…·éƒ½å¯ä»¥ä½¿ç”¨ã€‚</p>

    <p>æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„Sparkåº”ç”¨ç¨‹åº<code>SimpleApp.java</code>ï¼š</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="cm">/* SimpleApp.java */</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">SimpleApp</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="nc">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
    <span class="nc">String</span> <span class="n">logFile</span> <span class="o">=</span> <span class="s">"YOUR_SPARK_HOME/README.md"</span><span class="o">;</span> <span class="c1">// Should be some file on your system</span>
    <span class="nc">SparkSession</span> <span class="n">spark</span> <span class="o">=</span> <span class="nc">SparkSession</span><span class="o">.</span><span class="na">builder</span><span class="o">().</span><span class="na">appName</span><span class="o">(</span><span class="s">"Simple Application"</span><span class="o">).</span><span class="na">getOrCreate</span><span class="o">();</span>
    <span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">logData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">textFile</span><span class="o">(</span><span class="n">logFile</span><span class="o">).</span><span class="na">cache</span><span class="o">();</span>

    <span class="kt">long</span> <span class="n">numAs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="o">.</span><span class="na">contains</span><span class="o">(</span><span class="s">"a"</span><span class="o">)).</span><span class="na">count</span><span class="o">();</span>
    <span class="kt">long</span> <span class="n">numBs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="o">.</span><span class="na">contains</span><span class="o">(</span><span class="s">"b"</span><span class="o">)).</span><span class="na">count</span><span class="o">();</span>
    
    <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Lines with a: "</span> <span class="o">+</span> <span class="n">numAs</span> <span class="o">+</span> <span class="s">", lines with b: "</span> <span class="o">+</span> <span class="n">numBs</span><span class="o">);</span>
    
    <span class="n">spark</span><span class="o">.</span><span class="na">stop</span><span class="o">();</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

    <p>è¯¥ç¨‹åºåªè®¡ç®—SparkREADMEæ–‡ä»¶ä¸­åŒ…å«â€œ aâ€çš„è¡Œæ•°å’ŒåŒ…å«â€œ bâ€çš„è¡Œæ•°ã€‚è¯·æ³¨æ„ï¼Œä½ éœ€è¦å°†YOUR_SPARK_HOMEæ›¿æ¢ä¸ºè‡ªå·±ç”µè„‘ä¸­Sparkçš„å®‰è£…è·¯å¾„ã€‚ä¸å‰é¢å¸¦æœ‰Spark shellçš„ç¤ºä¾‹ï¼ˆå…¶åˆå§‹åŒ–å…¶è‡ªå·±çš„SparkSessionï¼‰ä¸åŒï¼Œæˆ‘ä»¬å°†SparkSessionåˆå§‹åŒ–ä¸ºç¨‹åºçš„ä¸€éƒ¨åˆ†ã€‚</p>

    <p>ä¸ºäº†æ„å»ºç¨‹åºï¼Œæˆ‘ä»¬è¿˜ç¼–å†™äº†ä¸€ä¸ªMaven <code>pom.xml</code>æ–‡ä»¶ï¼Œå…¶ä¸­å°†Sparkä½œä¸ºä¾èµ–é¡¹ã€‚è¯·æ³¨æ„ï¼ŒSpark artifactsä¸­å¸¦æœ‰Scalaç‰ˆæœ¬ä¿¡æ¯ã€‚</p>

    <figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;project&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>edu.berkeley<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>simple-project<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;modelVersion&gt;</span>4.0.0<span class="nt">&lt;/modelVersion&gt;</span>
  <span class="nt">&lt;name&gt;</span>Simple Project<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;packaging&gt;</span>jar<span class="nt">&lt;/packaging&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.0<span class="nt">&lt;/version&gt;</span>
  <span class="nt">&lt;dependencies&gt;</span>
    <span class="nt">&lt;dependency&gt;</span> <span class="c">&lt;!-- Spark dependency --&gt;</span>
      <span class="nt">&lt;groupId&gt;</span>org.apache.spark<span class="nt">&lt;/groupId&gt;</span>
      <span class="nt">&lt;artifactId&gt;</span>spark-sql_2.12<span class="nt">&lt;/artifactId&gt;</span>
      <span class="nt">&lt;version&gt;</span>3.0.0-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
      <span class="nt">&lt;scope&gt;</span>provided<span class="nt">&lt;/scope&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
  <span class="nt">&lt;/dependencies&gt;</span>
<span class="nt">&lt;/project&gt;</span></code></pre></figure>

    <p>æˆ‘ä»¬æ ¹æ®è§„èŒƒçš„Mavenç›®å½•ç»“æ„å¯¹è¿™äº›æ–‡ä»¶è¿›è¡Œå¸ƒå±€ï¼š</p>

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>find <span class="nb">.</span>
./pom.xml
./src
./src/main
./src/main/java
./src/main/java/SimpleApp.java</code></pre></figure>

    <p>ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Mavenæ‰“åŒ…åº”ç”¨ç¨‹åºå¹¶ä½¿ç”¨<code>./bin/spark-submit</code>æ¥æ‰§è¡Œå®ƒã€‚</p>

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># å°†ä½ çš„åº”ç”¨ç¨‹åºæ‰“æˆjaråŒ…</span>
<span class="nv">$ </span>mvn package
...
<span class="o">[</span>INFO] Building jar: <span class="o">{</span>..<span class="o">}</span>/<span class="o">{</span>..<span class="o">}</span>/target/simple-project-1.0.jar

<span class="c"># ä½¿ç”¨spark-submitè¿è¡Œä½ çš„ç¨‹åº</span>
<span class="nv">$ </span>YOUR_SPARK_HOME/bin/spark-submit <span class="se">\</span>
  <span class="nt">--class</span> <span class="s2">"SimpleApp"</span> <span class="se">\</span>
  <span class="nt">--master</span> <span class="nb">local</span><span class="o">[</span>4] <span class="se">\</span>
  target/simple-project-1.0.jar
...
Lines with a: 46, Lines with b: 23</code></pre></figure>

  </div>
<div data-lang="python">
    <p>ç°åœ¨ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨Python APIï¼ˆPySparkï¼‰ç¼–å†™åº”ç”¨ç¨‹åºã€‚</p>

    <p>å¦‚æœè¦æ„å»ºæ‰“åŒ…çš„PySparkåº”ç”¨ç¨‹åºæˆ–åº“ï¼Œåˆ™å¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼å°†å…¶æ·»åŠ åˆ°setup.pyæ–‡ä»¶ä¸­ï¼š</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">install_requires</span><span class="o">=</span><span class="p">[</span>
        <span class="s">'pyspark=={site.SPARK_VERSION}'</span>
    <span class="p">]</span></code></pre></figure>

    <p>ä½œä¸ºç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„Sparkåº”ç”¨ç¨‹åº<code>SimpleApp.py</code>ï¼š</p>

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="s">"""SimpleApp.py"""</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>

<span class="n">logFile</span> <span class="o">=</span> <span class="s">"YOUR_SPARK_HOME/README.md"</span>  <span class="c1"># Should be some file on your system
</span><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s">"SimpleApp"</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">logData</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">logFile</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

<span class="n">numAs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">logData</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'a'</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">numBs</span> <span class="o">=</span> <span class="n">logData</span><span class="o">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">logData</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'b'</span><span class="p">))</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Lines with a: </span><span class="si">%</span><span class="s">i, lines with b: </span><span class="si">%</span><span class="s">i"</span> <span class="o">%</span> <span class="p">(</span><span class="n">numAs</span><span class="p">,</span> <span class="n">numBs</span><span class="p">))</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span></code></pre></figure>

    <p>è¯¥ç¨‹åºåªè®¡ç®—æ–‡æœ¬æ–‡ä»¶ä¸­åŒ…å«â€œ aâ€çš„è¡Œæ•°å’ŒåŒ…å«â€œ bâ€çš„è¡Œæ•°ã€‚è¯·æ³¨æ„ï¼Œä½ éœ€è¦å°†YOUR_SPARK_HOMEæ›¿æ¢ä¸ºè‡ªå·±ç”µè„‘Sparkçš„å®‰è£…è·¯å¾„ã€‚ä¸Scalaå’ŒJavaç¤ºä¾‹ä¸€æ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨SparkSessionåˆ›å»ºDataSetã€‚å¯¹äºä½¿ç”¨è‡ªå®šä¹‰ç±»æˆ–ç¬¬ä¸‰æ–¹åº“çš„åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨<code>spark-submit</code>å°†å…¶æ‰“åŒ…åˆ°.zipæ–‡ä»¶ä¸­ï¼ŒåŒæ—¶ä½¿ç”¨å‚æ•°<code>--py-files</code>æŒ‡å®šä»£ç ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§<code>spark-submit --help</code>ã€‚ <code>SimpleApp</code>éå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä¸éœ€è¦æŒ‡å®šä»»ä½•ä»£ç ä¾èµ–é¡¹ã€‚</p>

    <p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹<code>bin/spark-submit</code>è„šæœ¬è¿è¡Œæ­¤åº”ç”¨ç¨‹åºï¼š</p>

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ä½¿ç”¨spark-submitè¿è¡Œä½ çš„ç¨‹åº</span>
<span class="nv">$ </span>YOUR_SPARK_HOME/bin/spark-submit <span class="se">\</span>
  <span class="nt">--master</span> <span class="nb">local</span><span class="o">[</span>4] <span class="se">\</span>
  SimpleApp.py
...
Lines with a: 46, Lines with b: 23</code></pre></figure>

    <p>If you have PySpark pip installed into your environment (e.g., <code>pip install pyspark</code>), you can run your application with the regular Python interpreter or use the provided &#8216;spark-submit&#8217; as you prefer.</p>

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># ä½¿ç”¨Pythonè§£é‡Šå™¨è¿è¡Œä½ çš„ç¨‹åº</span>
<span class="nv">$ </span>python SimpleApp.py
...
Lines with a: 46, Lines with b: 23</code></pre></figure>

  </div>
</div>

<h1 id="ä¸‹ä¸€æ­¥åšä»€ä¹ˆ">ä¸‹ä¸€æ­¥åšä»€ä¹ˆ</h1>
<p>ç¥è´ºä½ è¿è¡Œäº†ç¬¬ä¸€ä¸ªSparkåº”ç”¨ç¨‹åºï¼</p>

<ul>
  <li>æœ‰å…³APIçš„æ·±å…¥æ¦‚è¿°ï¼Œè¯·ä»<a href="rdd-programming-guide.html">RDDç¼–ç¨‹æŒ‡å—</a>å’Œ<a href="sql-programming-guide.html">SQLç¼–ç¨‹æŒ‡å—</a>å¼€å§‹ï¼Œæˆ–å‚é˜…â€œç¼–ç¨‹æŒ‡å—â€èœå•ä»¥è·å–å…¶ä»–ç»„ä»¶ã€‚</li>
  <li>è¦åœ¨é›†ç¾¤ä¸Šè¿è¡Œåº”ç”¨ç¨‹åºï¼Œè¯·è½¬è‡³<a href="cluster-overview.html">éƒ¨ç½²æ¦‚è¿°</a>ã€‚</li>
  <li>æœ€åï¼ŒSparkåœ¨<code>examples</code>ç›®å½•ï¼ˆ<a href="https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples">Scala</a>ï¼Œ <a href="https://github.com/apache/spark/tree/master/examples/src/main/java/org/apache/spark/examples">Java</a>ï¼Œ <a href="https://github.com/apache/spark/tree/master/examples/src/main/python">Python</a>ï¼Œ <a href="https://github.com/apache/spark/tree/master/examples/src/main/r">R</a>ï¼‰ä¸­åŒ…å«å‡ ä¸ªç¤ºä¾‹ã€‚ä½ å¯ä»¥æŒ‰ä¸‹é¢çš„æ–¹å¼è¿è¡Œå®ƒä»¬ï¼š</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># å¯¹äºScalaå’ŒJavaçš„ç¤ºä¾‹ï¼Œä½¿ç”¨run-exampleï¼š</span>
./bin/run-example SparkPi

<span class="c"># å¯¹äºPythonçš„ç¤ºä¾‹ï¼Œç›´æ¥ä½¿ç”¨ spark-submitï¼š</span>
./bin/spark-submit examples/src/main/python/pi.py

<span class="c"># å¯¹äºRè¯­è¨€çš„ç¤ºä¾‹ï¼Œç›´æ¥ä½¿ç”¨ spark-submitï¼š</span>

./bin/spark-submit examples/src/main/r/dataframe.R</code></pre></figure>
:ET