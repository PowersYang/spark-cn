(window.webpackJsonp=window.webpackJsonp||[]).push([[121],{318:function(e,r,t){"use strict";t.r(r);var a=t(0),n=Object(a.a)({},(function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"using-gpu-on-yarn"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#using-gpu-on-yarn","aria-hidden":"true"}},[e._v("#")]),e._v(" Using GPU On YARN")]),e._v(" "),t("h1",{attrs:{id:"prerequisites"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#prerequisites","aria-hidden":"true"}},[e._v("#")]),e._v(" Prerequisites")]),e._v(" "),t("ul",[t("li",[e._v("As of now, only Nvidia GPUs are supported by YARN")]),e._v(" "),t("li",[e._v("YARN node managers have to be pre-installed with Nvidia drivers.")]),e._v(" "),t("li",[e._v("When Docker is used as container runtime context, nvidia-docker 1.0 needs to be installed (Current supported version in YARN for nvidia-docker).")])]),e._v(" "),t("h1",{attrs:{id:"configs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#configs","aria-hidden":"true"}},[e._v("#")]),e._v(" Configs")]),e._v(" "),t("h2",{attrs:{id:"gpu-scheduling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gpu-scheduling","aria-hidden":"true"}},[e._v("#")]),e._v(" GPU scheduling")]),e._v(" "),t("p",[e._v("In resource-types.xml")]),e._v(" "),t("p",[e._v("Add following properties")]),e._v(" "),t("pre",[t("code",[e._v("<configuration>\n  <property>\n     <name>yarn.resource-types</name>\n     <value>yarn.io/gpu</value>\n  </property>\n</configuration>\n")])]),e._v(" "),t("p",[e._v("In yarn-site.xml")]),e._v(" "),t("p",[e._v("DominantResourceCalculator MUST be configured to enable GPU scheduling/isolation.")]),e._v(" "),t("p",[e._v("For Capacity Scheduler, use following property to configure DominantResourceCalculator (In capacity-scheduler.xml):")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("Default value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.scheduler.capacity.resource-calculator")]),e._v(" "),t("td",[e._v("org.apache.hadoop.yarn.util.resource.DominantResourceCalculator")])])])]),e._v(" "),t("h2",{attrs:{id:"gpu-isolation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gpu-isolation","aria-hidden":"true"}},[e._v("#")]),e._v(" GPU Isolation")]),e._v(" "),t("h3",{attrs:{id:"in-yarn-site-xml"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-yarn-site-xml","aria-hidden":"true"}},[e._v("#")]),e._v(" In yarn-site.xml")]),e._v(" "),t("pre",[t("code",[e._v("  <property>\n    <name>yarn.nodemanager.resource-plugins</name>\n    <value>yarn.io/gpu</value>\n  </property>\n")])]),e._v(" "),t("p",[e._v("This is to enable GPU isolation module on NodeManager side.")]),e._v(" "),t("p",[e._v("By default, YARN will automatically detect and config GPUs when above config is set. Following configs need to be set in yarn-site.xml only if admin has specialized requirements.")]),e._v(" "),t("ol",[t("li",[e._v("Allowed GPU Devices")])]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("Default value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices")]),e._v(" "),t("td",[e._v("auto")])])])]),e._v(" "),t("p",[e._v("Specify GPU devices which can be managed by YARN NodeManager (split by comma). Number of GPU devices will be reported to RM to make scheduling decisions. Set to auto (default) let YARN automatically discover GPU resource from system.")]),e._v(" "),t("p",[e._v("Manually specify GPU devices if auto detect GPU device failed or admin only want subset of GPU devices managed by YARN. GPU device is identified by their minor device number and index. A common approach to get minor device number of GPUs is using nvidia-smi -q and search Minor Number output.")]),e._v(" "),t("p",[e._v('When minor numbers are specified manually, admin needs to include indice of GPUs as well, format is index:minor_number[,index:minor_number...]. An example of manual specification is 0:0,1:1,2:2,3:4"to allow YARN NodeManager to manage GPU devices with indices 0/1/2/3 and minor number 0/1/2/4. numbers .')]),e._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[e._v("Executable to discover GPUs")])]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.nodemanager.resource-plugins.gpu.path-to-discovery-executables")]),e._v(" "),t("td",[e._v("/absolute/path/to/nvidia-smi")])])])]),e._v(" "),t("p",[e._v("When yarn.nodemanager.resource.gpu.allowed-gpu-devices=auto specified, YARN NodeManager needs to run GPU discovery binary (now only support nvidia-smi) to get GPU-related information. When value is empty (default), YARN NodeManager will try to locate discovery executable itself. An example of the config value is: /usr/local/bin/nvidia-smi")]),e._v(" "),t("ol",{attrs:{start:"3"}},[t("li",[e._v("Docker Plugin Related Configs")])]),e._v(" "),t("p",[e._v("Following configs can be customized when user needs to run GPU applications inside Docker container. Theyâ€™re not required if admin follows default installation/configuration of nvidia-docker.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("Default value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.nodemanager.resource-plugins.gpu.docker-plugin")]),e._v(" "),t("td",[e._v("nvidia-docker-v1")])])])]),e._v(" "),t("p",[e._v("Specify docker command plugin for GPU. By default uses Nvidia docker V1.0, nvidia-docker-v2 is available for V2.x.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("Default value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint")]),e._v(" "),t("td",[t("a",{attrs:{href:"http://localhost:3476/v1.0/docker/cli",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://localhost:3476/v1.0/docker/cli"),t("OutboundLink")],1)])])])]),e._v(" "),t("p",[e._v("Specify end point of nvidia-docker-plugin. Please find documentation: "),t("a",{attrs:{href:"https://github.com/NVIDIA/nvidia-docker/wiki",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://github.com/NVIDIA/nvidia-docker/wiki"),t("OutboundLink")],1),e._v(" For more details.")]),e._v(" "),t("ol",{attrs:{start:"4"}},[t("li",[e._v("CGroups mount")])]),e._v(" "),t("p",[e._v("GPU isolation uses CGroup "),t("a",{attrs:{href:"https://www.kernel.org/doc/Documentation/cgroup-v1/devices.txt",target:"_blank",rel:"noopener noreferrer"}},[e._v("devices controller"),t("OutboundLink")],1),e._v(" to do per-GPU device isolation. Following configs should be added to yarn-site.xml to automatically mount CGroup sub devices, otherwise admin has to manually create devices subfolder in order to use this feature.")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("Property")]),e._v(" "),t("th",[e._v("Default value")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("yarn.nodemanager.linux-container-executor.cgroups.mount")]),e._v(" "),t("td",[e._v("true")])])])]),e._v(" "),t("h3",{attrs:{id:"in-container-executor-cfg"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#in-container-executor-cfg","aria-hidden":"true"}},[e._v("#")]),e._v(" In container-executor.cfg")]),e._v(" "),t("p",[e._v("In general, following config needs to be added to container-executor.cfg")]),e._v(" "),t("pre",[t("code",[e._v("[gpu]\nmodule.enabled=true\n")])]),e._v(" "),t("p",[e._v("When user needs to run GPU applications under non-Docker environment:")]),e._v(" "),t("pre",[t("code",[e._v("[cgroups]\n# This should be same as yarn.nodemanager.linux-container-executor.cgroups.mount-path inside yarn-site.xml\nroot=/sys/fs/cgroup\n# This should be same as yarn.nodemanager.linux-container-executor.cgroups.hierarchy inside yarn-site.xml\nyarn-hierarchy=yarn\n")])]),e._v(" "),t("p",[e._v("When user needs to run GPU applications under Docker environment:")]),e._v(" "),t("ol",[t("li",[e._v("Add GPU related devices to docker section:")])]),e._v(" "),t("p",[e._v("Values separated by comma, you can get this by running ls /dev/nvidia*")]),e._v(" "),t("pre",[t("code",[e._v("[docker]\ndocker.allowed.devices=/dev/nvidiactl,/dev/nvidia-uvm,/dev/nvidia-uvm-tools,/dev/nvidia1,/dev/nvidia0\n")])]),e._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("p",[e._v("Add nvidia-docker to volume-driver whitelist.")]),e._v(" "),t("p",[e._v("[docker]\n...\ndocker.allowed.volume-drivers")])]),e._v(" "),t("li",[t("p",[e._v("Add nvidia_driver_"),t("version",[e._v(" to readonly mounts whitelist.")])],1),e._v(" "),t("p",[e._v("[docker]\n...\ndocker.allowed.ro-mounts=nvidia_driver_375.66")])]),e._v(" "),t("li",[t("p",[e._v("If use nvidia-docker-v2 as gpu docker plugin, add nvidia to runtimes whitelist.")]),e._v(" "),t("p",[e._v("[docker]\n...\ndocker.allowed.runtimes=nvidia")])])]),e._v(" "),t("h1",{attrs:{id:"use-it"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#use-it","aria-hidden":"true"}},[e._v("#")]),e._v(" Use it")]),e._v(" "),t("h2",{attrs:{id:"distributed-shell-gpu"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#distributed-shell-gpu","aria-hidden":"true"}},[e._v("#")]),e._v(" Distributed-shell + GPU")]),e._v(" "),t("p",[e._v("Distributed shell currently support specify additional resource types other than memory and vcores.")]),e._v(" "),t("h3",{attrs:{id:"distributed-shell-gpu-without-docker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#distributed-shell-gpu-without-docker","aria-hidden":"true"}},[e._v("#")]),e._v(" Distributed-shell + GPU without Docker")]),e._v(" "),t("p",[e._v("Run distributed shell without using docker container (Asks 2 tasks, each task has 3GB memory, 1 vcore, 2 GPU device resource):")]),e._v(" "),t("pre",[t("code",[e._v("yarn jar <path/to/hadoop-yarn-applications-distributedshell.jar> \\\n  -jar <path/to/hadoop-yarn-applications-distributedshell.jar> \\\n  -shell_command /usr/local/nvidia/bin/nvidia-smi \\\n  -container_resources memory-mb=3072,vcores=1,yarn.io/gpu=2 \\\n  -num_containers 2\n")])]),e._v(" "),t("p",[e._v("You should be able to see output like")]),e._v(" "),t("pre",[t("code",[e._v("Tue Dec  5 22:21:47 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 375.66                 Driver Version: 375.66                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 0000:04:00.0     Off |                    0 |\n| N/A   30C    P0    24W / 250W |      0MiB / 12193MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n|   1  Tesla P100-PCIE...  Off  | 0000:82:00.0     Off |                    0 |\n| N/A   34C    P0    25W / 250W |      0MiB / 12193MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n")])]),e._v(" "),t("p",[e._v("For launched container task.")]),e._v(" "),t("h3",{attrs:{id:"distributed-shell-gpu-with-docker"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#distributed-shell-gpu-with-docker","aria-hidden":"true"}},[e._v("#")]),e._v(" Distributed-shell + GPU with Docker")]),e._v(" "),t("p",[e._v("You can also run distributed shell with Docker container. YARN_CONTAINER_RUNTIME_TYPE/YARN_CONTAINER_RUNTIME_DOCKER_IMAGE must be specified to use docker container.")]),e._v(" "),t("pre",[t("code",[e._v("yarn jar <path/to/hadoop-yarn-applications-distributedshell.jar> \\\n       -jar <path/to/hadoop-yarn-applications-distributedshell.jar> \\\n       -shell_env YARN_CONTAINER_RUNTIME_TYPE=docker \\\n       -shell_env YARN_CONTAINER_RUNTIME_DOCKER_IMAGE=<docker-image-name> \\\n       -shell_command nvidia-smi \\\n       -container_resources memory-mb=3072,vcores=1,yarn.io/gpu=2 \\\n       -num_containers 2\n")])])])}),[],!1,null,null,null);r.default=n.exports}}]);