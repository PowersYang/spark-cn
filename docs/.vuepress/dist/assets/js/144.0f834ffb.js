(window.webpackJsonp=window.webpackJsonp||[]).push([[144],{341:function(e,o,t){"use strict";t.r(o);var i=t(0),n=Object(i.a)({},(function(){var e=this,o=e.$createElement,t=e._self._c||o;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"hadoop-archive-logs-guide"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-archive-logs-guide"}},[e._v("#")]),e._v(" Hadoop Archive Logs Guide")]),e._v(" "),t("h2",{attrs:{id:"overview"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#overview"}},[e._v("#")]),e._v(" Overview")]),e._v(" "),t("p",[e._v("For clusters with a lot of YARN aggregated logs, it can be helpful to combine them into hadoop archives in order to reduce the number of small files, and hence the stress on the NameNode. This tool provides an easy way to do this. Aggregated logs in hadoop archives can still be read by the Job History Server and by the "),t("code",[e._v("yarn logs")]),e._v(" command.")]),e._v(" "),t("p",[e._v("For more on hadoop archives, see "),t("router-link",{attrs:{to:"/en/docs/hadoop-archives/HadoopArchives.html"}},[e._v("Hadoop Archives Guide")]),e._v(".")],1),e._v(" "),t("h2",{attrs:{id:"how-to-archive-logs"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#how-to-archive-logs"}},[e._v("#")]),e._v(" How to Archive Logs")]),e._v(" "),t("pre",[t("code",[e._v("usage: mapred archive-logs\n-force                         Force recreating the working directory if\n                               an existing one is found. This should\n                               only be used if you know that another\n                               instance is not currently running\n-help                          Prints this message\n-maxEligibleApps <n>           The maximum number of eligible apps to\n                               process (default: -1 (all))\n-maxTotalLogsSize <megabytes>  The maximum total logs size (in\n                               megabytes) required to be eligible\n                               (default: 1024)\n-memory <megabytes>            The amount of memory (in megabytes) for\n                               each container (default: 1024)\n-minNumberLogFiles <n>         The minimum number of log files required\n                               to be eligible (default: 20)\n-noProxy                       When specified, all processing will be\n                               done as the user running this command (or\n                               the YARN user if DefaultContainerExecutor\n                               is in use). When not specified, all\n                               processing will be done as the user who\n                               owns that application; if the user\n                               running this command is not allowed to\n                               impersonate that user, it will fail\n-verbose                       Print more details.\n")])]),e._v(" "),t("p",[e._v("The tool only supports running one instance on a cluster at a time in order to prevent conflicts. It does this by checking for the existance of a directory named "),t("code",[e._v("archive-logs-work")]),e._v(" under "),t("code",[e._v("yarn.nodemanager.remote-app-log-dir")]),e._v(" in HDFS (default: "),t("code",[e._v("/tmp/logs/archive-logs-work")]),e._v("). If for some reason that directory was not cleaned up properly, and the tool refuses to run, you can force it with the "),t("code",[e._v("-force")]),e._v(" option.")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("-help")]),e._v(" option prints out the usage information.")]),e._v(" "),t("p",[e._v("The tool works by performing the following procedure:")]),e._v(" "),t("ol",[t("li",[e._v("Determine the list of eligible applications, based on the following criteria:")])]),e._v(" "),t("pre",[t("code",[e._v("* is not already archived\n* its aggregation status has successfully completed\n* has at least `-minNumberLogFiles` log files\n* the sum of its log files size is less than `-maxTotalLogsSize` megabytes\n")])]),e._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[e._v("If there are are more than "),t("code",[e._v("-maxEligibleApps")]),e._v(" applications found, the newest applications are dropped. They can be processed next time.")]),e._v(" "),t("li",[e._v("A shell script is generated based on the eligible applications")]),e._v(" "),t("li",[e._v("The Distributed Shell program is run with the aformentioned script. It will run with "),t("code",[e._v("-maxEligibleApps")]),e._v(" containers, one to process each application, and with "),t("code",[e._v("-memory")]),e._v(" megabytes of memory. Each container runs the "),t("code",[e._v("hadoop archives")]),e._v(" command for a single application and replaces its aggregated log files with the resulting archive.")])]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("-noProxy")]),e._v(" option makes the tool process everything as the user who is currently running it, or the YARN user if DefaultContainerExecutor is in use. When not specified, all processing will be done by the user who owns that application; if the user running this command is not allowed to impersonate that user, it will fail. This is useful if you want an admin user to handle all aggregation without enabling impersonation. With "),t("code",[e._v("-noProxy")]),e._v(" the resulting HAR files will be owned by whoever ran the tool, instead of whoever originally owned the logs.")]),e._v(" "),t("p",[e._v("The "),t("code",[e._v("-verbose")]),e._v(" option makes the tool print more details about what itâ€™s doing.")]),e._v(" "),t("p",[e._v("The end result of running the tool is that the original aggregated log files for a processed application will be replaced by a hadoop archive containing all of those logs.")])])}),[],!1,null,null,null);o.default=n.exports}}]);