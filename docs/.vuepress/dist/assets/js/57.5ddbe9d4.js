(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{257:function(t,o,e){"use strict";e.r(o);var s=e(0),i=Object(s.a)({},(function(){var t=this,o=t.$createElement,e=t._self._c||o;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"the-hadoop-filesystem-api-definition"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#the-hadoop-filesystem-api-definition","aria-hidden":"true"}},[t._v("#")]),t._v(" The Hadoop FileSystem API Definition")]),t._v(" "),e("p",[t._v("This is a specification of the Hadoop FileSystem APIs, which models the contents of a filesystem as a set of paths that are either directories, symbolic links, or files.")]),t._v(" "),e("p",[t._v("There is surprisingly little prior art in this area. There are multiple specifications of Unix filesystems as a tree of inodes, but nothing public which defines the notion of “Unix filesystem as a conceptual model for data storage access”.")]),t._v(" "),e("p",[t._v("This specification attempts to do that; to define the Hadoop FileSystem model and APIs so that multiple filesystems can implement the APIs and present a consistent model of their data to applications. It does not attempt to formally specify any of the concurrency behaviors of the filesystems, other than to document the behaviours exhibited by HDFS as these are commonly expected by Hadoop client applications.")]),t._v(" "),e("ol",[e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/introduction.html"}},[t._v("Introduction")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/notation.html"}},[t._v("Notation")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/model.html"}},[t._v("Model")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/filesystem.html"}},[t._v("FileSystem class")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/fsdatainputstream.html"}},[t._v("FSDataInputStream class")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/fsdataoutputstreambuilder.html"}},[t._v("FSDataOutputStreamBuilder class")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/testing.html"}},[t._v("Testing with the Filesystem specification")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/extending.html"}},[t._v("Extending the specification and its tests")])],1),t._v(" "),e("li",[e("router-link",{attrs:{to:"/docs/hadoop-project-dist/hadoop-common/filesystem/multipartuploader.html"}},[t._v("Uploading a file using Multiple Parts")])],1)])])}),[],!1,null,null,null);o.default=i.exports}}]);